# ETL-pipeline

<br />

<p align="center">
 <h2 align="center"><b>Data Modeling ETL with PostgreSQL</b></h2>
 <p align="center">
  Project in Data Engineer Nanodegree Course by Udacity
  <br />
 </p>



</p>

> Data Engineering, Data Modeling, Postgresql, Relational Databases, ETL, Star Schema Database, 



<!-- ABOUT THE PROJECT -->

## About The Project

<!-- Describing the project in brief -->

A startup called Sparkify wants to analyze the data they've been collecting on songs and user activity on their new music streaming application. The analytics team is particularly interested in understanding what songs users are listening to. Currently, they don't have an easy way to query their data, which resides in a directory of JSON logs on user activity on the application, as well as a directory with JSON meta-data on the songs in their application.

They'd like a data engineer to create a Postgres database with tables designed to optimize queries on song play analysis. The role of this project is to create a database schema and ETL pipeline for this analysis. 

### Project Description

In this project, we will model the data with Postgres and build an ETL pipeline using Python. The fact and dimension tables for a star database schema for a particular analytic focus is defined, and an ETL pipeline that transfers data from files in two local directories into these tables in Postgres using Python and SQL was developed.

### Built With:

* Python
* PostgreSQL
* Jupyter Notebooks

> You will not be able to run **test.ipynb**, **etl.ipynb**, or **etl.py** until you have run **create_tables.py** at least once to create the *sparkifydb* database, which these other files connect to. Always, close the connection to the database on exit. 

### Dataset
#### Song Dataset
Songs dataset is a subset of [Million Song Dataset](http://millionsongdataset.com/).  Each file in the dataset is in JSON format and contains meta-data about a song and the artist of that song. 

Sample Record :
```
{"num_songs": 1, "artist_id": "ARJIE2Y1187B994AB7", "artist_latitude": null, "artist_longitude": null, "artist_location": "", "artist_name": "Line Renaud", "song_id": "SOUPIRU12A6D4FA1E1", "title": "Der Kleine Dompfaff", "duration": 152.92036, "year": 0}
```

#### Log Dataset
Logs dataset is generated by [Event Simulator](https://github.com/Interana/eventsim).  These log files in JSON format simulate activity logs from a music streaming application based on specified configurations.

Sample Record :
```
{"artist": null, "auth": "Logged In", "firstName": "Walter", "gender": "M", "itemInSession": 0, "lastName": "Frye", "length": null, "level": "free", "location": "San Francisco-Oakland-Hayward, CA", "method": "GET","page": "Home", "registration": 1540919166796.0, "sessionId": 38, "song": null, "status": 200, "ts": 1541105830796, "userAgent": "\"Mozilla\/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/36.0.1985.143 Safari\/537.36\"", "userId": "39"}
```



## Database Schema Design

### Database Entity Relationship Diagram 

The scheme used in this project was the Star Schema where we have Song Plays as a fact table that contains all the metrics (facts) associated with each event (user actions) and four other dimension tables that contain data related to the user, artist, songs and time data such as day, hour, etc.

This approach is mostly used for relational data modeling, it allows us to have a search in a database using the minimum number of "Joins" in our queries which consequently generates quick reads.

In this project, the amount of data used is not large enough for us to use a big data or NoSQL database solution.

The Entity Relationship Diagram (ERD) of the data model is represented by the image
below:

![database](images/erd_p1.png)

## Project Structure

Repository:

| Files / Folders  |                                     Description                                              |
| :--------------: | :------------------------------------------------------------------------------------------: |
|    test.ipynb    | Displays the first few rows of each table to let you check your database.                    |
| create_tables.py | Drops, creates and also reseting.                                                            |
|    etl.ipynb     | Reads and processes a single file from song_data and log_data and loads the data into tables.|
|      etl.py      | Reads and processes files from song_data and log_data and loads them into your tables.       |
|  sql_queries.py  | Contains all your sql queries, and is imported into the last three files above.              |
|       data       | Folder at the root of the project, with all songs and logs data JSONS.                       |
|      images      | Folder with images used on the project.                                                      |
|    README.md     | File with all instructions and descriptions of the project.                                                                              



<!-- GETTING STARTED -->

## Getting Started

Clone the repository into a local machine using

```sh
git clone https://github.com/djanmagno/Udacity-Data-Engineer-Nanodegree
```

### Prerequisites

The prerequisites to run the program are:

* python 3.9+
* PostgreSQL
* psycopg2 python library
* pandas library

### How to run

Follow the steps below to extract and load the data into the sparkify database on Postgres.

1. Navigate to `Project-1-Data-Modeling-with-Postgres` folder

2. Run `create_tables.py` to create/reset the tables by

   ```python
   python3 create_tables.py
   ```

3. Run ETL process and load data into database by 

   ```python
   python3 etl.py
   ```

4. Check whether the data has been loaded into database by executing queries in `test.ipynb`

### Project Requirements

The requeriments for this project can be found on the image below.

![Requeriments](images/review.udacity.com_.png)

#### Query to evaluate the requeriment :
  - Itâ€™s okay if there are some null values for song titles and artist names in the songplays table. There is only 1 actual row that will have a songid and an artistid.

```
    SELECT * FROM songplays WHERE artist_id <> 'None';
```

<!-- LICENSE -->

## License

Distributed under the MIT License. See `LICENSE` for more information.


<!-- CONTACT -->

## Contact

Djan Magno - djan.magno@gmail.com

Project Link - [https://github.com/djanmagno/Udacity-Data-Engineer-Nanodegree/tree/master/Project-1-Data-Modeling-with-Postgres](https://github.com/djanmagno/Udacity-Data-Engineer-Nanodegree/tree/master/Project-1-Data-Modeling-with-Postgres)